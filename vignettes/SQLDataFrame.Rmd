---
title: "SQLDataFrame: Lazy representation of SQL database in DataFrame metaphor"
author:
- name: Qian Liu
  affiliation: Roswell Park Comprehensive Cancer Center, Buffalo, NY
- name: Martin Morgan
  affiliation: Roswell Park Comprehensive Cancer Center, Buffalo, NY
date: "last compiled: `r Sys.Date()`"
output:
    BiocStyle::html_document:
        toc: true
        toc_float: true
package: SQLDataFrame
vignette: >
  %\VignetteIndexEntry{SQLDataFrame: Lazy representation of SQL database in DataFrame metaphor}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
last edit: 01/06/2019

# Introduction

SQL database are very commonly used in the storage of very large
genomic data resources. Many useful tools, such as [DBI][], [dbplyr][]
have provided convenient interfaces for R users to check and
manipulate the data. These tools represent the SQL tables in tidy
formats and support lazy and quick aggregation operations (e.g,
`*_join`, `union`, etc.).

Since many of the existing and emerging bioinformatics tools are
adopting `DataFrame` structure, such as the [SummarizedExperiment][]
container, that many modern bioinformatics pipelines are based on for
representation of sequencing or genotyping experiments. The
interoperability of tidy tibbles with these tools are suboptimal. 

Building upon the existing [DBI][] and [dbplyr][] strategies, the
SQLDataFrame package was developed using familiar DataFrame-like
paradigm. It lazily represents medium to very large SQL tables from
diverse SQL database types, such as SQLite, MySQL and Google
BigQuery. The DataFrame-like interface provides familiarity for common
_R_ users in easy data manipulations such as square bracket
subsettings, etc. For modern _R_ users, it also recognizes the `tidy`
data analysis and [dplyr][] grammar by supporting `%>%`, `select`,
`filter`, `mutate`, and `*_join`.

The scalability, interoperability and functionality of SQLDataFrame
are expected to significantly promote the handling of very large
genomic data resources and facilitating the overall bioinformatics
analysis.

Currently SQLDataFrame supports the DBI backend of SQLite, MySQL and
Google BigQuery, which are most commonly used SQL-based databases. In
the future or upon feature request, we would implement this package so
that users could choose to use different database backend for
`SQLDataFrame` representation.

[DBI]: https://CRAN.R-project.org/package=DBI 
[dbplyr]:  https://CRAN.R-project.org/package=dbplyr
[dplyr]: https://CRAN.R-project.org/package=dplyr
[SummarizedExperiment]: https://bioconductor.org/packages/SummarizedExperiment/ 

# Installation

1. Download the package. 

```{r getPackage, eval=FALSE}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("SQLDataFrame")
```
The development version is also available to download from Github. 
```{r getDevel, eval=FALSE}
BiocManager::install("Bioconductor/SQLDataFrame")
```
2. Load the package(s) into R session.
```{r Load, message=FALSE, eval = TRUE}
library(SQLDataFrame)
library(DBI)
```

# `SQLDataFrame` class

## `SQLDataFrame` constructor
There are two ways to construct a `SQLDataFrame` object: 

1) Provide an argument of `conn`, `dbtable`, `dbkey`, and optionally
`partitionID`. `conn` is a valid DBIConnection from SQLite, MySQL or
Google BigQuery; `dbtable` specifies the database table name that is
going to be represented as `SQLDataFrame` object. If only one table is
available in the specified database name, it will be recognized when
this argument is blank. The `dbkey` argument is used to specify the
column name in the table which could uniquely identify all the data
observations (rows).

2) Provide `dbtable`, `dbkey` and optionally `partitionID` as
specified above, and credentials to build valid DBIConnections. for
SQLite, the credential argument includes `dbname`. For MySQL, the
credential arguments are `dbname`, `host`, `user`, `password`. For
Google BigQuery, the credentials are `host` (BigQuery project name),
`dbname` (BigQuery dataset name), and `billing` (BigQuery billing
project name). 

Additional to the credentials, users must provide the `type` argument
to specify the SQL database type. Supported types are "SQLite",
"MySQL" and "BigQuery". If not specified, "SQLite" is used by
default. Supported database tables could be on-disk or remote on the
web or cloud.

```{r constructor_conn}
dbfile <- system.file("extdata/test.db", package = "SQLDataFrame")
conn <- DBI::dbConnect(DBI::dbDriver("SQLite"), dbname = dbfile)
obj <- SQLDataFrame(conn = conn, dbtable = "state",
                    dbkey = "state")
```

construction from database credentials:
```{r constructor_credentials}
obj1 <- SQLDataFrame(dbname = dbfile, type = "SQLite",
                     dbtable = "state", dbkey = "state")
all.equal(obj, obj1)
```

Note that after reading the database table into `SQLDataFrame`, the
key columns will be kept as fixed columns showing on the left hand
side, with `|` separating key column(s) with the other columns. The
`ncol`, `colnames`, and corresponding column subsetting will only
apply to the non-key-columns. Key column names could be retrieved
using the slot accessor `dbkey()`.

```{r}
obj
dim(obj)
colnames(obj)
dbkey(obj)
```

## Slot & accessors

To make the `SQLDataFrame` object and operations as light possible,
there are 8 slots contained in the object as shown by `slotNames()`:
`tblData`, `keyData`, `dbkey`, `partitionID`, `pidRle` `ridx`, `dim`
and `dimnames`. Slot accessors and some utility functions are defined
to retrieve specific slots or other meta information. Details please
refer to the vignette of internal implementation in
"SQLDataFrame-internal". Here are several examples:

```{r}
slotNames(obj)
dbtable(obj)
dbkey(obj)
connSQLDataFrame(obj)
```

Besides, many useful common methods are defined on `SQLDataFrame`
object to make it a more DataFrame-like data structure. e.g., we can
use `dimnames()` to return the row/colnames of the data. It returns an
unnamed list, with the first element being rownames which is always
`NULL`, and 2nd element being colnames (could also use `colnames()`
method). `dim()` method is defined to return the dimension of the
database table, which enables the `nrow()/ncol()` to extract a
specific dimension. `length()` method is also defined which works same
as `ncol()`.  
Note that the `rownames(SQLDataFrame)` would always be `NULL` as
rownames are not supported in `SQLDataFrame`.
 
```{r methods}
dim(obj)
dimnames(obj)
length(obj)
```

**NOTE** that the `dbtable()` accessor only works for a `SQLDataFrame`
object that the lazy tbl carried in `tblData` slot corresponds to a
single database. If the `SQLDataFrame` was generated from `union` or
`*_join`, `dbtable()` doesn't work. 

```{r}
dbtable(obj)
aa <- union(obj[1:5, ], obj[6:10, ])
aa
dbtable(aa)  ## message
```

# makeSQLDataFrame

We could also construct a SQLDataFrame object directly from a in
memory data.frame or an on-disk file name. The `makeSQLDataFrame`
function takes input of character value of file name for common text
files (.csv, .txt, etc.), write into database tables, and open as
SQLDataFrame object. Users could provide values for the `dbname` and
`dbtable` arguments. If NULL, default value for `dbname` would be a
temporary database file, and `dbtable` would be the
`basename(filename)` without extension.

**NOTE** that the input file must have one or multiple columns that
could uniquely identify each observation (row) to be used the
`dbkey()` for SQLDataFrame. Also the file must be rectangular, i.e.,
rownames are not accepted. But users could save rownames as a separate
column. 

```{r}
mtc <- tibble::rownames_to_column(mtcars)[,1:6]
filename <- file.path(tempdir(), "mtc.csv")
write.csv(mtc, file= filename, row.names = FALSE)
aa <- makeSQLDataFrame(filename, dbkey = "rowname", sep = ",",
                       overwrite = TRUE)
aa
connSQLDataFrame(aa)
dbtable(aa)
```

# SQLDataFrame methods

## `[[` subsetting
`[[,SQLDataFrame` Behaves similarly to `[[,DataFrame` and returns a
realized vector of values from a single column. `$,SQLDataFrame` is
also defined to conveniently extract column values.

```{r}
head(obj[[1]])
head(obj[["region"]])
head(obj$size)
```

Although the key column doesn't count as column(s) in the SQLDataFrame
object, it is supported for the double square bracket extraction.

```{r}
head(obj[["state"]])
```

## `[` subsetting

SQLDataFrame instances can be subsetted in a similar way of DataFrame
following the usual _R_ conventions, with numeric, character or
logical vectors; logical vectors are recycled to the appropriate
length.

**NOTE**, use `drop=FALSE` explicitly for single column subsetting if
you want to return a SQLDataFrame object, otherwise, the default
`drop=TRUE` would always return a realized value for that column.

```{r, subsetting}
obj[1:3, 1:2]
obj[c(TRUE, FALSE), c(TRUE, FALSE), drop=FALSE]
obj[1:3, "population", drop=FALSE]
obj[, "population"]  ## realized column value
```

List style subsetting is also allowed to extract certain columns from
the `SQLDataFrame` object which returns `SQLDataFrame` by default.  

```{r}
obj[1]
obj["region"]
```

## select, filter, and mutate

We have also enabled the S3 methods of `%>%`, `select`, `filter` and
`mutate` from `dplyr` package, so that users could have the
convenience in selecting, filtering data observations or adding new
columns. Please note that the `filter` will not preserve any previous
arbitrary orders or duplicate rows. Details please refer to the
vignette for internal implementation.

```{r}
obj %>% select(division, population)
obj %>% filter(division == "South Atlantic" & size == "medium")
obj %>% mutate(p1 = population/10, s1 = size)
```

## union 

`union` method is implemented for SQLDataFrame, to combine and return unique
rows from the input SQLDataFrame(s). 

```{r}
obj_sub1 <- obj[1:10, ]
obj_sub2 <- obj[8:15, ]
union(obj_sub1, obj_sub2)
```

## *_join methods

The `*_join` family methods was implemented for SQLDataFrame objects,
including the `left_join`, `inner_join`, and filtering joins
`semi_join` and `anti_join`, which provides the capability of merging
and filtering database files. Note that the filtering joins use
`dbkey()` as the default common columns for joining.

```{r}
obj_sub3 <- obj[1:10, 1:2]
obj_sub4 <- obj[8:15, 3:4]
left_join(obj_sub3, obj_sub4)
inner_join(obj_sub3, obj_sub4)
semi_join(obj_sub3, obj_sub4)
anti_join(obj_sub3, obj_sub4)
```


# Support of MySQL database data

SQLDataFrame also supports the MySQL database tables through
[RMySQL][], for local MySQL servers, or remote ones on the web or
cloud. Here I'll show a simple use case for MySQL tables from ensembl. 

[RMySQL]: https://CRAN.R-project.org/package=RMySQL

```{r, mysql}
library(RMySQL)
ensbConn <- DBI::dbConnect(DBI::dbDriver("MySQL"),
                           host="genome-mysql.soe.ucsc.edu",
                           user = "genome",
                           dbname = "xenTro9")
enssdf <- SQLDataFrame(conn = ensbConn,
                       dbtable = "xenoRefGene",
                       dbkey = c("name", "txStart"))
enssdf1 <- enssdf[1:20, 1:2]
enssdf2 <- enssdf[11:30,3:4]
res <- left_join(enssdf1, enssdf2)
```

# Support of Google BigQuery 

SQLDataFrame has just added support for Google BigQuery
tables. Construction and queries using `[` and `filter` are supported!

"Authentication and authorization" will be needed when using
[bigrquery][]. Check [here](https://github.com/r-dbi/bigrquery) for
more details. 

[bigrquery]: https://CRAN.R-project.org/package=bigrquery

```{r bigquery, eval=FALSE}
library(bigrquery)
bigrquery::bq_auth()  ## use this to authorize bigrquery in the
                      ## browser.
bqConn <- DBI::dbConnect(DBI::dbDriver("bigquery"),
                      project = "bigquery-public-data",
                      dataset = "human_variant_annotation",
                      billing = "") ## if not previous provided
                                    ## authorization, must specify a
                                    ## project name that was already
                                    ## linked with Google Cloud with
                                    ## billing info.
bqsdf <- SQLDataFrame(conn = bqConn,
                      dbtable = "ncbi_clinvar_hg38_20180701",
                      dbkey = c("reference_name", "start_position", "end_position"))
bqsdf
bqsdf[1:5, 1:5]
bqsdf %>% filter(reference_name == "21") %>% select(5:10)
```

# SessionInfo()

```{r}
sessionInfo()
```
